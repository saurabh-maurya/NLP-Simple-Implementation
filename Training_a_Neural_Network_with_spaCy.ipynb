{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training a Neural Network with spaCy",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN831Kq7OrMxwOWDYPmDLfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh-maurya/NLP-Simple-Implementation/blob/master/Training_a_Neural_Network_with_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpAV72JWyNP1",
        "colab_type": "text"
      },
      "source": [
        "# Creating Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHK4EcQ3lS4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "with open(\"exercises/en/iphone.json\") as f:\n",
        "    TEXTS = json.loads(f.read())\n",
        "\n",
        "nlp = English()\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
        "pattern1 = [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
        "\n",
        "# Token whose lowercase form matches \"iphone\" and a digit\n",
        "pattern2 = [{'LOWER': 'iphone'}, {'is_digit': True}]\n",
        "\n",
        "# Add patterns to the matcher and check the result\n",
        "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
        "for doc in nlp.pipe(TEXTS):\n",
        "    print([doc[start:end] for match_id, start, end in matcher(doc)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cvdjwyqzHGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "with open(\"exercises/en/iphone.json\") as f:\n",
        "    TEXTS = json.loads(f.read())\n",
        "\n",
        "nlp = English()\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
        "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
        "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
        "\n",
        "TRAINING_DATA = []\n",
        "\n",
        "# Create a Doc object for each text in TEXTS\n",
        "for doc in nlp.pipe(TEXTS):\n",
        "    # Match on the doc and create a list of matched spans\n",
        "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
        "    # Get (start character, end character, label) tuples of matches\n",
        "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
        "    # Format the matches as a (doc.text, entities) tuple\n",
        "    training_example = (doc.text, {\"entities\": entities})\n",
        "    # Append the example to the training data\n",
        "    TRAINING_DATA.append(training_example)\n",
        "\n",
        "print(*TRAINING_DATA, sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmD_CElozg0b",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQdCxe-p46Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "​\n",
        "# Create a blank \"en\" model\n",
        "nlp = spacy.blank(\"en\")\n",
        "​\n",
        "# Create a new entity recognizer and add it to the pipeline\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "nlp.add_pipe(ner)\n",
        "​\n",
        "# Add the label \"GADGET\" to the entity recognizer\n",
        "ner.add_label(\"GADGET\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFZaO3Bz4_QN",
        "colab_type": "text"
      },
      "source": [
        "# Building a Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBy9Xvan5FBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "import json\n",
        "\n",
        "with open(\"exercises/en/gadgets.json\") as f:\n",
        "    TRAINING_DATA = json.loads(f.read())\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "nlp.add_pipe(ner)\n",
        "ner.add_label(\"GADGET\")\n",
        "\n",
        "# Start the training\n",
        "nlp.begin_training()\n",
        "\n",
        "# Loop for 10 iterations\n",
        "for itn in range(10):\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAINING_DATA)\n",
        "    losses = {}\n",
        "\n",
        "    # Batch the examples and iterate over them\n",
        "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
        "        texts = [text for text, entities in batch]\n",
        "        annotations = [entities for text, entities in batch]\n",
        "\n",
        "        # Update the model\n",
        "        nlp.update(texts, annotations, losses=losses)\n",
        "    print(losses)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}