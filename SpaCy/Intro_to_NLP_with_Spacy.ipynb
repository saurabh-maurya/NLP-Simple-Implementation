{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to NLP with Spacy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvuAGF6nR08nmWipNnfms/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh-maurya/NLP-Simple-Implementation/blob/master/Intro_to_NLP_with_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkoUwmyNKv8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import spacy\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plIJMCU_QLl5",
        "colab_type": "text"
      },
      "source": [
        "spaCy relies on models that are language-specific and come in different sizes. You can load a spaCy model with **spacy.load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-R5Rw3UQVd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load english language\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_F6snQ0Qdw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text process\n",
        "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY6_O-KaQkEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "7ea1549a-5c37-4119-e583-2201f9a15228"
      },
      "source": [
        "# we can do lot with doc object that we have jcreated above\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tea\n",
            "is\n",
            "healthy\n",
            "and\n",
            "calming\n",
            ",\n",
            "do\n",
            "n't\n",
            "you\n",
            "think\n",
            "?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8a3idYYQqz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "38e531f2-6d17-4f91-ec51-f9f24731344b"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.lemma_) #lemmatizing"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tea\n",
            "be\n",
            "healthy\n",
            "and\n",
            "calm\n",
            ",\n",
            "do\n",
            "not\n",
            "-PRON-\n",
            "think\n",
            "?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4OPcsjSRHD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "609169d8-6c5c-4b77-a3a1-f1dfb821176c"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.is_stop) # stop word"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEWhhfsjRMLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "431ab128-a4dd-4422-8ad5-9791a58099ba"
      },
      "source": [
        "# visualizing token, lemma and stop word\n",
        "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
        "print(\"-\"*40)\n",
        "for token in doc:\n",
        "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token \t\tLemma \t\tStopword\n",
            "----------------------------------------\n",
            "Tea\t\ttea\t\tFalse\n",
            "is\t\tbe\t\tTrue\n",
            "healthy\t\thealthy\t\tFalse\n",
            "and\t\tand\t\tTrue\n",
            "calming\t\tcalm\t\tFalse\n",
            ",\t\t,\t\tFalse\n",
            "do\t\tdo\t\tTrue\n",
            "n't\t\tnot\t\tTrue\n",
            "you\t\t-PRON-\t\tTrue\n",
            "think\t\tthink\t\tFalse\n",
            "?\t\t?\t\tFalse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90TeGPW8SB3U",
        "colab_type": "text"
      },
      "source": [
        "**lemmatizing** and **dropping stopwords** might result in your models performing **worse**. So you should treat this preprocessing as part of your **hyperparameter optimization process**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdA89oJBRrtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Patter Matching\n",
        "#------------------------------------------------------------------------------------------------------------------------\n",
        "# You can do pattern matching with regular expressions, but spaCy's matching capabilities tend to be easier to use....\n",
        "\n",
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGDjJn6DUvtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of terms to match in the text\n",
        "# The phrase matcher needs the patterns as document objects\n",
        "# The easiest way to get these is with a list comprehension using the nlp model.\n",
        "\n",
        "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
        "patterns = [nlp(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", None, *patterns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcTD0kblVEYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddf36ed8-5a81-4bcb-e2cc-1b10a28760a6"
      },
      "source": [
        "# create a document from the text to search and use the phrase matcher to find where the terms occur in the text\n",
        "\n",
        "# Borrowed from https://daringfireball.net/linked/2019/09/21/patel-11-pro\n",
        "\n",
        "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
        "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
        "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\") \n",
        "matches = matcher(text_doc)\n",
        "print(matches)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq9DvEXsVO_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed770462-d0e4-45ac-ea6b-af0c95400291"
      },
      "source": [
        "# The matches here are a tuple of the match id and the positions of the start and end of the phrase.\n",
        "\n",
        "match_id, start, end = matches[0]\n",
        "print(nlp.vocab.strings[match_id], text_doc[start:end])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TerminologyList iPhone 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1xRk9qXdQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}